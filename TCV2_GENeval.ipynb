{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCV2_GENeval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RVS97/MNIST-GANs/blob/master/TCV2_GENeval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dXfPHKYmWa8",
        "colab_type": "text"
      },
      "source": [
        "Evaluate strength of different generators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AGyWHFDSkOU",
        "colab_type": "text"
      },
      "source": [
        "#Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjHiS7drSevw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.utils import to_categorical\n",
        "from tensorflow.python.keras.optimizers import Adam, SGD\n",
        "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose \n",
        "from tensorflow.python.keras.layers import Input, UpSampling2D, concatenate  \n",
        "from tensorflow.python.keras.layers import LeakyReLU\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from matplotlib import pyplot\n",
        "from math import ceil\n",
        "from scipy.stats import describe\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pickle\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCfRosi9Sp2g",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdsj7GdYSwnE",
        "colab_type": "code",
        "outputId": "9035e4f3-ebbb-4354-ac5f-aaac788d9128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "rootDir = \"/content/rootDir\"\n",
        "subrootDir = rootDir + \"/Bonus\"\n",
        "!mkdir $subrootDir\n",
        "\n",
        "def saveFile(filePath, rootDir):\n",
        "  !cp $filePath $rootDir\n",
        "  \n",
        "def getFile(fileName, rootDir, localDir = \"./\"):\n",
        "  path = rootDir + \"/\" + fileName\n",
        "  !cp $path $localDir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/content/gdrive/My Drive/TCV2/Bonus’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1rNJdcQS-3Y",
        "colab_type": "text"
      },
      "source": [
        "#Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LzILGwFUfJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNoiseCGAN(size, seed=-1):\n",
        "  numEls = size[0]\n",
        "  labels = np.zeros(numEls, 'uint8')\n",
        "  labelsPerClass = int(numEls/10)\n",
        "  for i in range(1,10):\n",
        "    labels[labelsPerClass*i:labelsPerClass*(i+1)] = i\n",
        "  \n",
        "  if seed != -1:\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "  return np.random.normal(size=size), to_categorical(labels, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvkCes70oRuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNoise(size):\n",
        "    return np.random.normal(size=size), to_categorical(np.random.randint(0,10,(1,size[0])), num_classes=10)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e02T6eUnJnsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getAccAndConf(predProbsAllOrg, gtLabelsAllOrg, batchSize=100):\n",
        "  predProbsAll = np.copy(predProbsAllOrg)\n",
        "  gtLabelsAll = np.copy(gtLabelsAllOrg)\n",
        "  # predLables and gtLabels in one-hot encoding form\n",
        "  N = len(predProbsAll)\n",
        "  nClasses = len(predProbsAll[0])\n",
        "\n",
        "  nBatches = int(N/batchSize)\n",
        "\n",
        "  correctCount = 0\n",
        "  confCorrect = 0\n",
        "  confIncorrect = 0\n",
        "  for batchId in range(nBatches):\n",
        "    gtLabels = gtLabelsAll[batchId*batchSize:(batchId+1)*batchSize]\n",
        "    predProbs = np.reshape(predProbsAll[batchId*batchSize:(batchId+1)*batchSize], (1, batchSize))\n",
        "\n",
        "    # Get ground truth labels in decimal\n",
        "    gtLabelsDec = gtLabels\n",
        "\n",
        "    # Get classification labels\n",
        "    predLabelsDec = np.copy(predProbs)\n",
        "\n",
        "    predLabelsDec[predLabelsDec>=0.5]=1\n",
        "    predLabelsDec[predLabelsDec<0.5]=0\n",
        "\n",
        "\n",
        "    # Get indices of correctly/incorrect classified samples\n",
        "    correctIdx0 = np.where(np.logical_and(predLabelsDec==0,gtLabelsDec==0))\n",
        "    correctIdx1 = np.where(np.logical_and(predLabelsDec==1,gtLabelsDec==1))\n",
        "    incorrectIdx0 = np.where(np.logical_and(predLabelsDec==1,gtLabelsDec==0))\n",
        "    incorrectIdx1 = np.where(np.logical_and(predLabelsDec==0,gtLabelsDec==1))\n",
        "\n",
        "    # Get accuracy\n",
        "    nCorrect = len(correctIdx0[0]) + len(correctIdx1[0])\n",
        "    nIncorrect = len(incorrectIdx0[0]) + len(incorrectIdx1[0])\n",
        "    correctCount += nCorrect\n",
        "    #print(correctCount)\n",
        "\n",
        "    # Get samples that have been correctly/incorrectly classified\n",
        "    correctSamples0 = predProbs[correctIdx0]\n",
        "    correctSamples1 = predProbs[correctIdx1]\n",
        "    incorrectSamples0 = predProbs[incorrectIdx0]\n",
        "    incorrectSamples1 = predProbs[incorrectIdx1]\n",
        "\n",
        "    # Get confidences\n",
        "    if nCorrect != 0:\n",
        "      confCorrect += np.sum(correctSamples1) + np.sum(1-correctSamples0)\n",
        "      #print(confCorrect)\n",
        "\n",
        "    if nIncorrect != 0:\n",
        "      confIncorrect += np.sum(incorrectSamples1) + np.sum(1-incorrectSamples0)\n",
        "\n",
        "  acc = correctCount/N\n",
        "  if correctCount == 0:\n",
        "    confCorrect = 0\n",
        "  else:\n",
        "    confCorrect = confCorrect/correctCount\n",
        "  \n",
        "  if N-correctCount == 0:\n",
        "    confIncorrect = 0\n",
        "  else:\n",
        "    confIncorrect = confIncorrect/(N-correctCount)\n",
        "    \n",
        "  return acc, confCorrect, confIncorrect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEGgByf6WC3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folders = ['07_11h_35m','07_12h_09m','07_12h_54m','07_13h_53m','07_14h_53m','07_16h_09m'] # Deep network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmUSSAjtUkw-",
        "colab_type": "code",
        "outputId": "39f97c6d-3922-480d-feea-903114a4bc07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# strong discriminator\n",
        "targetDir = \"/content/gdrive/My Drive/TCV2/cGAN\"\n",
        "# folder = '07_13h_53m' #cGAN k=2 b=0.9\n",
        "folder = folders[4]\n",
        "# folder = '07_12h_32m'#'07_12h_09m' #cGAN k=1 b=0.9\n",
        "\n",
        "\n",
        "# Set number of data samples to test\n",
        "numEls = 10000\n",
        "\n",
        "# Set target epoch number\n",
        "targetEpoch = 15\n",
        "\n",
        "# Get noise input\n",
        "# noiseVec, fakeLabels = getNoiseCGAN((numEls, 100), seed=1010101)\n",
        "noiseVec, fakeLabels = getNoise((numEls, 100))\n",
        "\n",
        "# Download strong model\n",
        "targetFolder = \"\\\"\" + targetDir + \"/\" + folder + \"\\\"\"\n",
        "targetFile = folder + \"_gan_\" + str(targetEpoch) + \".h5\"\n",
        "getFile(targetFile, targetFolder)\n",
        "\n",
        "# Load gan\n",
        "model = load_model(targetFile)\n",
        "\n",
        "# Load discriminator\n",
        "disc = model.layers[3]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Fc5hGASAn8",
        "colab_type": "code",
        "outputId": "10d8d374-a70f-4507-e75d-c306bdd0f397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(values.shape)\n",
        "valuesAccum = np.zeros((10000,1))\n",
        "print(valuesAccum.shape)\n",
        "valuesAccum[2] = 3\n",
        "print(valuesAccum[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 1)\n",
            "(10000, 1)\n",
            "[3.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B9OxU0eXNtT",
        "colab_type": "code",
        "outputId": "7ebb52b9-71d1-4120-9eda-0a7b9e138165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "source": [
        "folders = ['07_11h_35m','07_12h_09m','07_12h_54m','07_13h_53m','07_14h_53m','07_16h_09m'] # Deep network\n",
        "# folders = ['07_11h_56m','07_12h_32m','07_13h_10m','07_17h_06m','07_17h_44m','07_18h_29m'] # Shallow network\n",
        "losses = np.zeros(len(folders))\n",
        "valuesAccum = np.zeros((10000,1))\n",
        "\n",
        "for i,f in enumerate(folders):\n",
        "  print(f)\n",
        "  # load other GAN models\n",
        "  targetFolder = \"\\\"\" + targetDir + \"/\" + f + \"\\\"\"\n",
        "  targetFile = f + \"_gan_\" + str(targetEpoch) + \".h5\"\n",
        "  getFile(targetFile, targetFolder)\n",
        "\n",
        "  model = load_model(targetFile)\n",
        "  # Extract generators and merge with discriminator\n",
        "  gen = model.layers[2]\n",
        "  \n",
        "  noiseInput = Input(shape=(100,))\n",
        "  labelInput = Input(shape=(10,))\n",
        "  \n",
        "  genGAN = gen([noiseInput, labelInput])\n",
        "  out = disc([genGAN, labelInput])\n",
        "  gan = Model([noiseInput, labelInput], out, name=\"gan\")\n",
        "  \n",
        "  # Evaluate GAN loss on noise\n",
        "  values = gan.predict([noiseVec, fakeLabels])\n",
        "  valuesAccum += values\n",
        "  [acc, confC, confI] = getAccAndConf(values, np.zeros(10000))\n",
        "  \n",
        "  losses[i] = acc\n",
        "  print(acc)\n",
        "valuesAccum = valuesAccum/len(folders)\n",
        "[acc2, confC2, confI2] = getAccAndConf(valuesAccum, np.zeros(10000))\n",
        "losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07_11h_35m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.9999\n",
            "07_12h_09m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.9999\n",
            "07_12h_54m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.9999\n",
            "07_13h_53m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "1.0\n",
            "07_14h_53m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.9999\n",
            "07_16h_09m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9999, 0.9999, 0.9999, 1.    , 0.9999, 1.    ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrlVdLl5TkMH",
        "colab_type": "code",
        "outputId": "e3d4ae37-5126-4f5a-da24-46eca2c8d706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "acc2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    }
  ]
}