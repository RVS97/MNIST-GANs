{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DISCeval.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RVS97/MNIST-GANs/blob/master/DISCeval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMpSCfR3kx4l",
        "colab_type": "text"
      },
      "source": [
        "Evaluate strength of different discriminators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "djWavmH8ajxk"
      },
      "source": [
        "#Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NEje_D9Zajxs",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.utils import to_categorical\n",
        "from tensorflow.python.keras.optimizers import Adam, SGD\n",
        "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose \n",
        "from tensorflow.python.keras.layers import Input, UpSampling2D, concatenate  \n",
        "from tensorflow.python.keras.layers import LeakyReLU\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from matplotlib import pyplot\n",
        "from math import ceil\n",
        "from scipy.stats import describe\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pickle\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OYB5GXDxajyA"
      },
      "source": [
        "# Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f92d1c01-226e-40e3-cf7b-492a7cbc68e8",
        "id": "sP-gtuJOajyE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "rootDir = \"/content/gdrive/My\\ Drive/TCV2\"\n",
        "subrootDir = rootDir + \"/Bonus\"\n",
        "!mkdir $subrootDir\n",
        "\n",
        "def saveFile(filePath, rootDir):\n",
        "  !cp $filePath $rootDir\n",
        "  \n",
        "def getFile(fileName, rootDir, localDir = \"./\"):\n",
        "  path = rootDir + \"/\" + fileName\n",
        "  !cp $path $localDir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "mkdir: cannot create directory ‘/content/gdrive/My Drive/TCV2/Bonus’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K0xpViUcajyY"
      },
      "source": [
        "#Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I7mymZRBajya",
        "colab": {}
      },
      "source": [
        "def getNoiseCGAN(size, seed=-1):\n",
        "  numEls = size[0]\n",
        "  labels = np.zeros(numEls, 'uint8')\n",
        "  labelsPerClass = int(numEls/10)\n",
        "  for i in range(1,10):\n",
        "    labels[labelsPerClass*i:labelsPerClass*(i+1)] = i\n",
        "  \n",
        "  if seed != -1:\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "  return np.random.normal(size=size), to_categorical(labels, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SRfs7Ma6ajye",
        "colab": {}
      },
      "source": [
        "def getNoise(size):\n",
        "    return np.random.normal(size=size), to_categorical(np.random.randint(0,10,(1,size[0])), num_classes=10)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NrgZ1muGajzU",
        "colab": {}
      },
      "source": [
        "def getAccAndConf(predProbsAllOrg, gtLabelsAllOrg, batchSize=100):\n",
        "  predProbsAll = np.copy(predProbsAllOrg)\n",
        "  gtLabelsAll = np.copy(gtLabelsAllOrg)\n",
        "  # predLables and gtLabels in one-hot encoding form\n",
        "  N = len(predProbsAll)\n",
        "  nClasses = len(predProbsAll[0])\n",
        "\n",
        "  nBatches = int(N/batchSize)\n",
        "\n",
        "  correctCount = 0\n",
        "  confCorrect = 0\n",
        "  confIncorrect = 0\n",
        "  for batchId in range(nBatches):\n",
        "    gtLabels = gtLabelsAll[batchId*batchSize:(batchId+1)*batchSize]\n",
        "    predProbs = np.reshape(predProbsAll[batchId*batchSize:(batchId+1)*batchSize], (1, batchSize))\n",
        "\n",
        "    # Get ground truth labels in decimal\n",
        "    gtLabelsDec = gtLabels\n",
        "\n",
        "    # Get classification labels\n",
        "    predLabelsDec = np.copy(predProbs)\n",
        "\n",
        "    predLabelsDec[predLabelsDec>=0.5]=1\n",
        "    predLabelsDec[predLabelsDec<0.5]=0\n",
        "\n",
        "\n",
        "    # Get indices of correctly/incorrect classified samples\n",
        "    correctIdx0 = np.where(np.logical_and(predLabelsDec==0,gtLabelsDec==0))\n",
        "    correctIdx1 = np.where(np.logical_and(predLabelsDec==1,gtLabelsDec==1))\n",
        "    incorrectIdx0 = np.where(np.logical_and(predLabelsDec==1,gtLabelsDec==0))\n",
        "    incorrectIdx1 = np.where(np.logical_and(predLabelsDec==0,gtLabelsDec==1))\n",
        "\n",
        "    # Get accuracy\n",
        "    nCorrect = len(correctIdx0[0]) + len(correctIdx1[0])\n",
        "    nIncorrect = len(incorrectIdx0[0]) + len(incorrectIdx1[0])\n",
        "    correctCount += nCorrect\n",
        "    #print(correctCount)\n",
        "\n",
        "    # Get samples that have been correctly/incorrectly classified\n",
        "    correctSamples0 = predProbs[correctIdx0]\n",
        "    correctSamples1 = predProbs[correctIdx1]\n",
        "    incorrectSamples0 = predProbs[incorrectIdx0]\n",
        "    incorrectSamples1 = predProbs[incorrectIdx1]\n",
        "\n",
        "    # Get confidences\n",
        "    if nCorrect != 0:\n",
        "      confCorrect += np.sum(correctSamples1) + np.sum(1-correctSamples0)\n",
        "      #print(confCorrect)\n",
        "\n",
        "    if nIncorrect != 0:\n",
        "      confIncorrect += np.sum(incorrectSamples1) + np.sum(1-incorrectSamples0)\n",
        "\n",
        "  acc = correctCount/N\n",
        "  if correctCount == 0:\n",
        "    confCorrect = 0\n",
        "  else:\n",
        "    confCorrect = confCorrect/correctCount\n",
        "  \n",
        "  if N-correctCount == 0:\n",
        "    confIncorrect = 0\n",
        "  else:\n",
        "    confIncorrect = confIncorrect/(N-correctCount)\n",
        "    \n",
        "  return acc, confCorrect, confIncorrect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DrTigmC4ajze",
        "colab": {}
      },
      "source": [
        "# folders = ['07_11h_35m','07_12h_09m','07_12h_54m','07_13h_53m','07_14h_53m','07_16h_09m'] # Deep network\n",
        "folders = ['07_11h_56m','07_12h_32m','07_13h_10m','07_17h_06m','07_17h_44m','07_18h_29m'] # Shallow network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "62956950-8949-4d09-f2a5-927530718b58",
        "id": "YlA24DJfaj0I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# strong discriminator\n",
        "targetDir = \"/content/gdrive/My Drive/TCV2/cGAN2\" #1=deep\n",
        "folder = folders[3]\n",
        "\n",
        "\n",
        "# Set number of data samples to test\n",
        "numEls = 10000\n",
        "\n",
        "# Set target epoch number\n",
        "targetEpoch = 15\n",
        "\n",
        "# Get noise input\n",
        "# noiseVec, fakeLabels = getNoiseCGAN((numEls, 100), seed=1010101)\n",
        "noiseVec, fakeLabels = getNoise((numEls, 100))\n",
        "\n",
        "# Download strong model\n",
        "targetFolder = \"\\\"\" + targetDir + \"/\" + folder + \"\\\"\"\n",
        "targetFile = folder + \"_gan_\" + str(targetEpoch) + \".h5\"\n",
        "getFile(targetFile, targetFolder)\n",
        "\n",
        "# Load gan\n",
        "model = load_model(targetFile)\n",
        "\n",
        "# Load generator\n",
        "gen = model.layers[2]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "10d8d374-a70f-4507-e75d-c306bdd0f397",
        "id": "DCXrpj1aaj0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(values.shape)\n",
        "valuesAccum = np.zeros((10000,1))\n",
        "print(valuesAccum.shape)\n",
        "valuesAccum[2] = 3\n",
        "print(valuesAccum[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 1)\n",
            "(10000, 1)\n",
            "[3.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "87c50a64-df8f-4dc6-b9b5-a21c9b144941",
        "id": "Ma6zno2Uaj01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "\n",
        "losses = np.zeros(len(folders))\n",
        "valuesAccum = np.zeros((10000,1))\n",
        "\n",
        "for i,f in enumerate(folders):\n",
        "  print(f)\n",
        "  # load other GAN models\n",
        "  targetFolder = \"\\\"\" + targetDir + \"/\" + f + \"\\\"\"\n",
        "  targetFile = f + \"_gan_\" + str(targetEpoch) + \".h5\"\n",
        "  getFile(targetFile, targetFolder)\n",
        "\n",
        "  model = load_model(targetFile)\n",
        "  # Extract discriminator and merge with generator\n",
        "  disc = model.layers[3]\n",
        "  \n",
        "  noiseInput = Input(shape=(100,))\n",
        "  labelInput = Input(shape=(10,))\n",
        "  \n",
        "  genGAN = gen([noiseInput, labelInput])\n",
        "  out = disc([genGAN, labelInput])\n",
        "  gan = Model([noiseInput, labelInput], out, name=\"gan\")\n",
        "  \n",
        "  # Evaluate GAN loss on noise\n",
        "  values = gan.predict([noiseVec, fakeLabels])\n",
        "  valuesAccum += values\n",
        "  [acc, confC, confI] = getAccAndConf(values, np.zeros(10000))\n",
        "  \n",
        "  losses[i] = acc\n",
        "  print(acc)\n",
        "valuesAccum = valuesAccum/len(folders)\n",
        "[acc2, confC2, confI2] = getAccAndConf(valuesAccum, np.zeros(10000))\n",
        "losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07_11h_56m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.9493\n",
            "07_12h_32m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.6912\n",
            "07_13h_10m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.5178\n",
            "07_17h_06m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.4353\n",
            "07_17h_44m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "1.0\n",
            "07_18h_29m\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "0.9994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9493, 0.6912, 0.5178, 0.4353, 1.    , 0.9994])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2dc3af3f-6a51-463a-c61a-db1021038e2c",
        "id": "53oGU8tVaj1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "acc2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}
