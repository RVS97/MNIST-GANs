{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCV2 - cGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RVS97/MNIST-GANs/blob/master/TCV2_cGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7DGZy7LKQlt",
        "colab_type": "text"
      },
      "source": [
        "# Libraries\n",
        "Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E86SZ7erKOPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import tensorflow.python.keras\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.utils import to_categorical\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape, Add\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose \n",
        "from tensorflow.python.keras.layers import Input, UpSampling2D, concatenate  \n",
        "from tensorflow.python.keras.layers import LeakyReLU\n",
        "from tensorflow.python.keras.layers.merge import concatenate\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from matplotlib import pyplot\n",
        "import datetime\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ia_JrjEIA3I",
        "colab_type": "text"
      },
      "source": [
        "# Dataset\n",
        "Import MNIST dataset from keras and map image values to 0/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkUJdBbEGzwC",
        "colab_type": "code",
        "outputId": "2c920ba2-d3d5-420e-9da2-a8241eff0a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Import dataset\n",
        "from keras.datasets import mnist\n",
        "\n",
        "class MNISTdata:\n",
        "  def __init__(self, batchSize=100, shuffle=True):\n",
        "\n",
        "    # Load into variables\n",
        "    (self.x_train, self.y_train),(self.x_test, self.y_test) = mnist.load_data()\n",
        "    \n",
        "    self.x_train = np.expand_dims(self.x_train, -1)\n",
        "    self.x_test = np.expand_dims(self.x_test, -1)\n",
        "    \n",
        "    # One-hot encode labels\n",
        "    self.y_train = to_categorical(self.y_train, num_classes=10)\n",
        "    self.y_test = to_categorical(self.y_test, num_classes=10)\n",
        "    \n",
        "    # Map image values to the range -1/1\n",
        "    self.x_train = (self.x_train.astype(np.float32) - 127.5)/127.5*-1\n",
        "    self.x_test = (self.x_test.astype(np.float32) - 127.5)/127.5*-1#R\n",
        "    #self.x_train, self.x_test = self.x_train/255.0, self.x_test/255.0\n",
        "\n",
        "    self.imgWidth = len(self.x_train[0][0])\n",
        "    self.imgHeight = len(self.x_train[0])\n",
        "    self.nTrainSamples = len(self.x_train)\n",
        "    self.nTestSamples = len(self.x_test)\n",
        "    \n",
        "    print(\"MNIST loaded correctly\")\n",
        "    print(\" - {} by {} images (grayscale)\".format(self.imgWidth,self.imgHeight))\n",
        "    print(\" - {} training samples\".format(self.nTrainSamples))\n",
        "    print(\" - {} test samples\".format(self.nTestSamples))\n",
        "    \n",
        "    self.batchSize = batchSize\n",
        "    self.nBatches = int(self.nTrainSamples/self.batchSize)\n",
        "    \n",
        "    print(\"Batch size {} -> {} batches\".format(self.batchSize, self.nBatches))\n",
        "    \n",
        "    if shuffle: self.shuffleData()\n",
        "  \n",
        "  def shuffleData(self):\n",
        "    self.x_train, self.y_train = shuffle(self.x_train, self.y_train)\n",
        "    \n",
        "  def getBatch(self, batchId):\n",
        "    return self.x_train[batchId*self.batchSize:(batchId+1)*self.batchSize], self.y_train[batchId*self.batchSize:(batchId+1)*self.batchSize]\n",
        "    \n",
        "data = MNISTdata(batchSize=200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "MNIST loaded correctly\n",
            " - 28 by 28 images (grayscale)\n",
            " - 60000 training samples\n",
            " - 10000 test samples\n",
            "Batch size 200 -> 300 batches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63m9Xzv7DP5L",
        "colab_type": "text"
      },
      "source": [
        "# Model Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wBxP4cWDQSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class modelData:\n",
        "  def __init__(self, model, modelId='auto'):\n",
        "    # Save model structure\n",
        "    self.jsonStructure = model.to_json()\n",
        "    \n",
        "    # Set model id (defaut is timestamp of creation)\n",
        "    if modelId == 'auto':\n",
        "      self.modelId = self.setId()\n",
        "    else:\n",
        "      self.modelId = modelId\n",
        "    \n",
        "    # Set saved epoch counter to 0\n",
        "    self.currentEpoch = 0\n",
        "    self.epochsHist = {}\n",
        "    \n",
        "    self.params = {}\n",
        "    \n",
        "  def setId(self):\n",
        "    return datetime.datetime.now().strftime(\"%d_%Hh_%Mm\")\n",
        "  \n",
        "  def getId(self):\n",
        "    return self.modelId\n",
        "  \n",
        "  def addEpochCheckpoint(self, model, hist):\n",
        "    # Save weights\n",
        "    self.currentEpoch += 1\n",
        "    \n",
        "    # Save history\n",
        "    self.epochsHist[self.currentEpoch] = hist.history\n",
        "    \n",
        "    # Save model\n",
        "    saveName = self.modelId + \"_\" + model.name + \"_\" + str(self.currentEpoch) + \".h5\"\n",
        "    model.save(saveName)\n",
        "    return saveName\n",
        "  \n",
        "  def saveParams(self, **params):\n",
        "    self.params.update(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Maww0KaHDcjJ",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive Mount\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGX5kdG8Dc7o",
        "colab_type": "code",
        "outputId": "ce276d1d-06ec-41ad-f3a9-a5087e822d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "rootDir = \"/content/rootDir\"\n",
        "\n",
        "def saveFile(filePath, rootDir):\n",
        "  !cp $filePath $rootDir\n",
        "  \n",
        "def getFile(fileName, rootDir, localDir = \"./\"):\n",
        "  path = rootDir + \"/\" + fileName\n",
        "  !cp $path $localDir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4mPjDCdbz3r",
        "colab_type": "text"
      },
      "source": [
        "# Generator and Discriminator\n",
        "Define generator and discriminator network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6re2OLtkuv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDiscriminator(imageInputShape=(28,28,1), labelInputShape=(10,)):\n",
        "  # Model for image input\n",
        "  modelImageIn = Input(shape=imageInputShape)\n",
        "  x = Conv2D(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(modelImageIn)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = BatchNormalization(axis=-1)(x)\n",
        "  modelImage = Model(modelImageIn, x)\n",
        "  \n",
        "  # Model for label input\n",
        "  modelLabelIn = Input(shape=labelInputShape)\n",
        "  y = Dense(14*14*32, activation='relu', name='InputDenseb', kernel_initializer='glorot_uniform')(modelLabelIn)\n",
        "  y = BatchNormalization(axis=-1)(y)\n",
        "  y = Reshape((14, 14, 32), name='InputReshapeb')(y)\n",
        "  \n",
        "#   y = Conv2D(64, (3, 3), padding='same', activation=LeakyReLU(alpha=0.2), kernel_initializer='glorot_uniform')(y)\n",
        "#   y = BatchNormalization(axis=-1)(y)\n",
        "  modelLabel = Model(modelLabelIn, y)\n",
        "  \n",
        "  # Merged\n",
        "  concat = concatenate([x, y])\n",
        "  out = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(concat)\n",
        "  out = LeakyReLU(alpha=0.2)(out)\n",
        "  out = BatchNormalization(axis=-1)(out)\n",
        "  \n",
        "  out = Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(out)\n",
        "  out = LeakyReLU(alpha=0.2)(out)\n",
        "  out = BatchNormalization(axis=-1)(out)\n",
        "  \n",
        "  out = Flatten()(out)\n",
        "  out = Dense(1, activation='sigmoid')(out)\n",
        "  \n",
        "  mergedModel = Model([modelImageIn, modelLabelIn], out, name=\"Discriminator\")\n",
        "  \n",
        "  return mergedModel\n",
        "\n",
        "\n",
        "\n",
        "def getDiscriminator2(imageInputShape=(28,28,1), labelInputShape=(10,)):\n",
        "  # Model for image input\n",
        "  modelImageIn = Input(shape=imageInputShape)\n",
        "  x = Conv2D(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(modelImageIn)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  x = BatchNormalization(axis=-1)(x)\n",
        "  modelImage = Model(modelImageIn, x)\n",
        "  \n",
        "  # Model for label input\n",
        "  modelLabelIn = Input(shape=labelInputShape)\n",
        "  y = Dense(14*14*32, activation='relu', name='InputDenseb', kernel_initializer='glorot_uniform')(modelLabelIn)\n",
        "  y = BatchNormalization(axis=-1)(y)\n",
        "  y = Reshape((14, 14, 32), name='InputReshapeb')(y)\n",
        "  \n",
        "#   y = Conv2D(64, (3, 3), padding='same', activation=LeakyReLU(alpha=0.2), kernel_initializer='glorot_uniform')(y)\n",
        "#   y = BatchNormalization(axis=-1)(y)\n",
        "  modelLabel = Model(modelLabelIn, y)\n",
        "  \n",
        "  # Merged\n",
        "  concat = concatenate([x, y])\n",
        "  out = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer='glorot_uniform')(concat)\n",
        "  out = LeakyReLU(alpha=0.2)(out)\n",
        "  out = BatchNormalization(axis=-1)(out)\n",
        "  \n",
        "  out = Flatten()(out)\n",
        "  out = Dense(1, activation='sigmoid')(out)\n",
        "  \n",
        "  mergedModel = Model([modelImageIn, modelLabelIn], out, name=\"Discriminator\")\n",
        "  \n",
        "  return mergedModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3j6gTM7nm-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7kmucwar3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getGenerator(noiseInputShape=(100,), labelInputShape=(10,)):\n",
        "  # Model for noise input\n",
        "  modelNoiseIn = Input(shape=noiseInputShape)\n",
        "  x = Dense(7*7*256, activation='relu', name='InputDense', kernel_initializer='glorot_uniform')(modelNoiseIn)\n",
        "  x = BatchNormalization(axis=-1)(x)\n",
        "  x = Reshape((7, 7, 256), name='InputReshape')(x)\n",
        "  \n",
        "#   x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu', name='tConv1', kernel_initializer='glorot_uniform')(x)\n",
        "#   x = BatchNormalization(axis=-1)(x)\n",
        "  modelNoise = Model(modelNoiseIn, x)\n",
        "  \n",
        "  # Model for label input\n",
        "  modelLabelIn = Input(shape=labelInputShape)\n",
        "  y = Dense(7*7*256, activation='relu', name='InputDenseb', kernel_initializer='glorot_uniform')(modelLabelIn)\n",
        "  y = BatchNormalization(axis=-1)(y)\n",
        "  y = Reshape((7, 7, 256), name='InputReshapeb')(y)\n",
        "  \n",
        "#   y = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu', name='tConv1b', kernel_initializer='glorot_uniform')(y)\n",
        "#   y = BatchNormalization(axis=-1)(y)\n",
        "  modelLabel = Model(modelLabelIn, y)\n",
        "  \n",
        "  # Concatenation layer\n",
        "  concat = concatenate([x, y])\n",
        "  \n",
        "  out = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu', name='tConv1', kernel_initializer='glorot_uniform')(concat)\n",
        "  out = BatchNormalization(axis=-1)(out)\n",
        "  \n",
        "  out = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu', name='tConv2b', kernel_initializer='glorot_uniform')(out)\n",
        "  out = BatchNormalization(axis=-1)(out)\n",
        "  \n",
        "  out = Conv2D(1, (3, 3), padding='same', activation='tanh', name='outConvb', kernel_initializer='glorot_uniform')(out)\n",
        "  \n",
        "  mergedModel = Model([modelNoiseIn, modelLabelIn], out, name=\"Generator\")\n",
        "  \n",
        "  return mergedModel\n",
        "\n",
        "def getGenerator2(noiseInputShape=(100,), labelInputShape=(10,)):\n",
        "  # Model for noise input\n",
        "  modelNoiseIn = Input(shape=noiseInputShape)\n",
        "  x = Dense(7*7*128, activation='relu', name='InputDense', kernel_initializer='glorot_uniform')(modelNoiseIn)\n",
        "  x = BatchNormalization(axis=-1)(x)\n",
        "  x = Reshape((7, 7, 128), name='InputReshape')(x)\n",
        "  \n",
        "#   x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu', name='tConv1', kernel_initializer='glorot_uniform')(x)\n",
        "#   x = BatchNormalization(axis=-1)(x)\n",
        "  modelNoise = Model(modelNoiseIn, x)\n",
        "  \n",
        "  # Model for label input\n",
        "  modelLabelIn = Input(shape=labelInputShape)\n",
        "  y = Dense(7*7*128, activation='relu', name='InputDenseb', kernel_initializer='glorot_uniform')(modelLabelIn)\n",
        "  y = BatchNormalization(axis=-1)(y)\n",
        "  y = Reshape((7, 7, 128), name='InputReshapeb')(y)\n",
        "  \n",
        "#   y = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu', name='tConv1b', kernel_initializer='glorot_uniform')(y)\n",
        "#   y = BatchNormalization(axis=-1)(y)\n",
        "  modelLabel = Model(modelLabelIn, y)\n",
        "  \n",
        "  # Concatenation layer\n",
        "  concat = concatenate([x, y])\n",
        "  \n",
        "  out = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu', name='tConv1', kernel_initializer='glorot_uniform')(concat)\n",
        "  out = BatchNormalization(axis=-1)(out)\n",
        "  \n",
        "  out = Conv2D(1, (3, 3), padding='same', activation='tanh', name='outConvb', kernel_initializer='glorot_uniform')(out)\n",
        "  \n",
        "  mergedModel = Model([modelNoiseIn, modelLabelIn], out, name=\"Generator\")\n",
        "  \n",
        "  return mergedModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD8pr4iRprO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getNoise(size):\n",
        "    return np.random.normal(size=size), to_categorical(np.random.randint(0,10,(1,size[0])), num_classes=10)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pToJCeBPpscL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainDiscriminator(model, data, labels):\n",
        "  # Reset optmizer state?\n",
        "  \n",
        "  # Return loss\n",
        "  return model.fit(x=data, y=labels, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htz25p_sd5mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainGenerator(model, fakeData, labels):\n",
        "  # Reset optimizer state?\n",
        "  \n",
        "  # Classify data with discriminator model\n",
        "  loss = model.fit(x=fakeData, y=labels, verbose=0)\n",
        "  \n",
        "  return loss\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQlrALA8pIvs",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iSfTvOAkn-0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrmzosoECImK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class paramSearch:\n",
        "  def  __init__(self, K, optTypes, learnRate, beta1):\n",
        "    self.K = K\n",
        "    self.optTypes = optTypes\n",
        "    self.learnRate = learnRate\n",
        "    self.beta1 = beta1\n",
        "    \n",
        "  def getParams(self):\n",
        "    for k in self.K:\n",
        "      for opt in self.optTypes:\n",
        "        if opt == 'sgd':\n",
        "          for lr in self.learnRate:\n",
        "            yield k, opt, lr\n",
        "        else:\n",
        "          for b1 in self.beta1:\n",
        "            yield k, opt, b1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEeiObqCuMYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noiseVecLength = 100\n",
        "\n",
        "# pS = paramSearch(K=[1, 2, 3], optTypes=['sgd', 'adam'], learnRate=[0.0001, 0.00001], beta1=[0.5, 0.9])\n",
        "pS = paramSearch(K=[1, 2, 3], optTypes=['adam'], learnRate=[0.1], beta1=[0.5, 0.9])\n",
        "pS = paramSearch(K=[1], optTypes=['adam'], learnRate=[0.1], beta1=[0.5])\n",
        "for k, opt, param in pS.getParams():\n",
        "  epochs = 3\n",
        "  \n",
        "  # Redefine models to clear\n",
        "  disc = getDiscriminator()\n",
        "  discData = modelData(disc)\n",
        "  \n",
        "  # Get generator\n",
        "  gen = getGenerator()\n",
        "  \n",
        "  # Get complete GAN\n",
        "  noiseInput = Input(shape=(100,))\n",
        "  labelInput = Input(shape=(10,))\n",
        "\n",
        "  genGAN = gen([noiseInput, labelInput])\n",
        "  out = disc([genGAN, labelInput])\n",
        "  gan = Model([noiseInput, labelInput], out, name=\"gan\")\n",
        "  ganData = modelData(gan, modelId=discData.getId())\n",
        "  \n",
        "  # Save K\n",
        "  K = k\n",
        "  discData.saveParams(K=K)\n",
        "  \n",
        "  # Specify and save optimiser\n",
        "  optimiser = Adam(lr=0.0002, beta_1=param, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "  discData.saveParams(optType='adam', opt=optimiser.get_config())\n",
        "\n",
        "  # Compile models\n",
        "  disc.compile(optimizer=optimiser, loss='binary_crossentropy')\n",
        "  discData.saveParams(loss=disc.loss)\n",
        "  \n",
        "  gan.layers[-1].trainable=False # Lock discriminator\n",
        "  gan.compile(optimizer=optimiser, loss='binary_crossentropy')\n",
        "  ganData.saveParams(loss=gan.loss)\n",
        "  \n",
        "  # Create folder where to save model\n",
        "  subDir = rootDir + \"/\" + discData.getId()\n",
        "  !mkdir $subDir\n",
        "  \n",
        "  # Train\n",
        "  for e in range(epochs):\n",
        "    print(str(e))\n",
        "    \n",
        "    # Shuffle batches\n",
        "    data.shuffleData()\n",
        "    \n",
        "    # Iterations\n",
        "    for iter in range(data.nBatches):\n",
        "      for k in range(K):\n",
        "        # Get real data\n",
        "        realImages, realLabels = data.getBatch(iter)\n",
        "\n",
        "        # Get fake data\n",
        "        noiseInput, noiseLabels = getNoise((data.batchSize, noiseVecLength))\n",
        "#         print(noiseInput.shape)\n",
        "#         print(noiseLabels.shape)\n",
        "#         print(data.batchSize)\n",
        "        fakeImages = gen.predict([noiseInput, noiseLabels], batch_size=data.batchSize)\n",
        "        fakeLabels = np.zeros((data.batchSize,))\n",
        "\n",
        "#         histDisc = trainDiscriminator(disc, [realImages, realLabels], np.ones((data.batchSize,)))\n",
        "#         histDisc2 = trainDiscriminator(disc, [fakeImages, noiseLabels], fakeLabels)\n",
        "        # Train discriminator\n",
        "        allImages = np.concatenate((realImages, fakeImages))\n",
        "        classLabels = np.concatenate((realLabels, noiseLabels))                        # 0 to 9 to specify class\n",
        "        discriminatorLabels = np.concatenate((np.ones((data.batchSize,)), fakeLabels)) # 0 or 1 to determine if fake or real\n",
        "        histDisc = trainDiscriminator(disc, [allImages, classLabels], discriminatorLabels)\n",
        "        \n",
        "      # Train generator\n",
        "      noiseInput, noiseLabels = getNoise((data.batchSize, noiseVecLength))\n",
        "      fakeLabels = np.ones((data.batchSize,))\n",
        "      histGan = trainGenerator(gan, [noiseInput, noiseLabels], fakeLabels)\n",
        "\n",
        "      if iter%200 == 0:\n",
        "        print(\"Discriminator: {}  Generator: {}\".format(histDisc.history['loss'], histGan.history['loss']))\n",
        "        \n",
        "    # Save discriminator\n",
        "    savedDiscName = discData.addEpochCheckpoint(disc, histDisc)\n",
        "    discDataName = discData.getId() + \"_\" + disc.name + \"_data.pkl\"\n",
        "    with open(discDataName, 'wb') as f:\n",
        "      pickle.dump(discData, f)\n",
        "\n",
        "    saveFile(savedDiscName, subDir)\n",
        "    saveFile(discDataName, subDir)\n",
        "\n",
        "    # Save gan\n",
        "    savedGanName = ganData.addEpochCheckpoint(gan, histGan)\n",
        "    ganDataName = ganData.getId() + \"_\" + gan.name + \"_data.pkl\"\n",
        "    with open(ganDataName, 'wb') as f:\n",
        "      pickle.dump(ganData, f)\n",
        "\n",
        "    saveFile(savedGanName, subDir)\n",
        "    saveFile(ganDataName, subDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcbL-aviznaE",
        "colab_type": "code",
        "outputId": "f506c5a8-294f-45d2-a298-5b51c51410df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(realImages.shape)\n",
        "print(fakeImages.shape)\n",
        "print(allImages.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 28, 28, 1)\n",
            "(200, 28, 28, 1)\n",
            "(400, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiLJgDwIr8Vp",
        "colab_type": "code",
        "outputId": "5a1df869-8f02-487c-ad1b-091904e29427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1401
        }
      },
      "source": [
        "disc = getDiscriminator()\n",
        "#adam = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #R\n",
        "gen = getGenerator()\n",
        "gen.summary()\n",
        "#gen.compile(optimizer=adam, loss='binary_crossentropy') #R\n",
        "#disc.compile(optimizer=adam, loss='binary_crossentropy') #R\n",
        "\n",
        "noiseInput = Input(shape=(100,))\n",
        "labelInput = Input(shape=(10,))\n",
        "\n",
        "genGAN = gen([noiseInput, labelInput])\n",
        "out = disc([genGAN, labelInput])\n",
        "gan = Model([noiseInput, labelInput], out)\n",
        "gan.summary()\n",
        "# descGan = disc\n",
        "# gan = disc\n",
        "# gan = Model([(100,), (10,)])\n",
        "# gan.add(gen)\n",
        "# gan.add(disc)\n",
        "# gan.summary()\n",
        "\n",
        "epochs = 3\n",
        "K = 1\n",
        "noiseVecLength = 100\n",
        "\n",
        "adam = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "disc.compile(optimizer=adam, loss='binary_crossentropy')\n",
        "\n",
        "gan.layers[-1].trainable=False\n",
        "gan.compile(optimizer=adam, loss='binary_crossentropy')\n",
        "gan.layers[-1].trainable=True #R\n",
        "for e in range(epochs):\n",
        "  print(str(e))\n",
        "  data.shuffleData()\n",
        "  for iter in range(data.nBatches):\n",
        "    for k in range(K):\n",
        "      # Get real data\n",
        "      realImages, realLabels = data.getBatch(iter)\n",
        "      \n",
        "      #realLabels = y_train[batchIdxs]\n",
        "\n",
        "      noiseInput, noiseLabels = getNoise((data.batchSize, noiseVecLength))\n",
        "      \n",
        "      fakeImages = gen.predict([noiseInput, noiseLabels], batch_size=data.batchSize)\n",
        "      fakeLabels = np.zeros((data.batchSize,))\n",
        "      \n",
        "      histDisc1 = trainDiscriminator(disc, [realImages, realLabels], np.ones((data.batchSize,)))\n",
        "      histDisc2 = trainDiscriminator(disc, [fakeImages, noiseLabels], fakeLabels)\n",
        "      \n",
        "      pyplot.imshow(np.squeeze(fakeImages[0]))\n",
        "      \n",
        "    noiseInput, noiseLabels = getNoise((data.batchSize, noiseVecLength))\n",
        "    fakeLabels = np.ones((data.batchSize,))\n",
        "    \n",
        "    gan.layers[-1].trainable=False #R\n",
        "    histGen = trainGenerator(gan, [noiseInput, noiseLabels], fakeLabels)\n",
        "    gan.layers[-1].trainable=True #R\n",
        "    \n",
        "    if iter%200 == 0:\n",
        "      print(\"Discriminator: {}, {}  Generator: {}\".format(histDisc1.history['loss'], histDisc2.history['loss'], histGen.history['loss']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "InputDense (Dense)              (None, 12544)        1266944     input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "InputDenseb (Dense)             (None, 12544)        137984      input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 12544)        50176       InputDense[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 12544)        50176       InputDenseb[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "InputReshape (Reshape)          (None, 7, 7, 256)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "InputReshapeb (Reshape)         (None, 7, 7, 256)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 7, 7, 512)    0           InputReshape[0][0]               \n",
            "                                                                 InputReshapeb[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tConv1 (Conv2DTranspose)        (None, 14, 14, 128)  589952      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 14, 14, 128)  512         tConv1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tConv2b (Conv2DTranspose)       (None, 28, 28, 64)   73792       batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 28, 28, 64)   256         tConv2b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "outConvb (Conv2D)               (None, 28, 28, 1)    577         batch_normalization_v1_37[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 2,170,369\n",
            "Trainable params: 2,119,809\n",
            "Non-trainable params: 50,560\n",
            "__________________________________________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_24 (InputLayer)           (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Generator (Model)               (None, 28, 28, 1)    2170369     input_23[0][0]                   \n",
            "                                                                 input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Discriminator (Model)           (None, 1)            506497      Generator[1][0]                  \n",
            "                                                                 input_24[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,676,866\n",
            "Trainable params: 2,612,866\n",
            "Non-trainable params: 64,000\n",
            "__________________________________________________________________________________________________\n",
            "0\n",
            "Discriminator: [0.1554187087994069], [0.28355317924171686]  Generator: [0.7366735851764679]\n",
            "Discriminator: [0.3848058784008026], [0.4390275728702545]  Generator: [3.1018050479888917]\n",
            "1\n",
            "Discriminator: [0.3121085584163666], [0.4256308755278587]  Generator: [3.5945830726623536]\n",
            "Discriminator: [0.21578695595264435], [0.24533755511045455]  Generator: [4.3742601013183595]\n",
            "2\n",
            "Discriminator: [0.44209526062011717], [0.47806019231677055]  Generator: [4.395427589416504]\n",
            "Discriminator: [0.5580360782146454], [0.4242898728698492]  Generator: [3.8265739822387697]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQFgCgMH/AeXnvbRiw2p2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjbge4qFDNDN",
        "colab_type": "code",
        "outputId": "e168870a-7f50-47f2-ddaf-a7415af7f235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "gan.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_103 (InputLayer)          (None, 100)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_104 (InputLayer)          (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_117 (Model)               (None, 28, 28, 1)    2170369     input_103[0][0]                  \n",
            "                                                                 input_104[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Discriminator (Model)           (None, 1)            506497      model_117[1][0]                  \n",
            "                                                                 input_104[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,676,866\n",
            "Trainable params: 2,119,809\n",
            "Non-trainable params: 557,057\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btzazjaLv6Q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noiseLabels = to_categorical(np.ones(data.batchSize), num_classes=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLAzS5xFIOL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag = \"06_22h_18m\"\n",
        "getFile(tag + \"_gan_5.h5\", rootDir + \"/\" + tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGaX0NXrIZfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.set_weights(keras.models.load_model(tag + \"_gan_5.h5\").get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGVXHnP1dHhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noiseInput, noiseLabels = getNoise((data.batchSize, noiseVecLength))\n",
        "noiseLabels = to_categorical(np.ones(data.batchSize)*5, num_classes=10) # multiply times label\n",
        "fakeImages = gen.predict([noiseInput, noiseLabels], batch_size=data.batchSize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD1D-5iaDkny",
        "colab_type": "code",
        "outputId": "46f2bf27-b212-42c3-e61f-824701f343c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# Check example generated digit for given (above) label\n",
        "id = 12\n",
        "print(noiseLabels[id])\n",
        "pyplot.imshow(np.squeeze(fakeImages[id]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4b832b71d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAADwhIADAhLADAgLAHAgLAEAIP/A/yEdI0HcAsWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}